{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking PyTorch and CUDA Version, and GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1+cu124\n",
      "CUDA version: 12.4\n",
      "Is GPU available: True\n",
      "GPU Device Name: NVIDIA GeForce RTX 2070\n",
      "Device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Is GPU available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Required Libraries for Data Loading and GPT-2 Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and Evaluating a Foundation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading and Preparing AG News Dataset for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "[Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 120000\n",
      "}), Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 7600\n",
      "})] \n",
      "\n",
      "\n",
      "Number of training examples: 120000\n",
      "Number of test examples: 7600\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "seed = 42\n",
    "\n",
    "# load the dataset https://huggingface.co/datasets/fancyzhx/ag_news\n",
    "try:\n",
    "    dataset = load_dataset('ag_news', split=['train', 'test'])\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except Exception as ex:\n",
    "    print(f\"An error occurred while loading the dataset: {ex}\")\n",
    "# NOTE: ag_news is a dataset of news articles classified into four categories: World, Sports, Business, and Sci/Tech.\n",
    "\n",
    "# print the dataset\n",
    "# NOTE: training examples: 120,000; test examples: 7,600\n",
    "print(dataset, '\\n\\n')\n",
    "\n",
    "# shuffle the training dataset \n",
    "num_train_samples = None  # use all training samples\n",
    "num_test_samples = None  # use all test samples\n",
    "\n",
    "# get training examples\n",
    "if num_train_samples is None:\n",
    "    train_dataset = dataset[0].shuffle(seed=seed)\n",
    "else:\n",
    "    train_dataset = dataset[0].shuffle(seed=seed).select(range(num_train_samples))\n",
    "\n",
    "# get test examples\n",
    "if num_test_samples is None:\n",
    "    test_dataset = dataset[1]\n",
    "else:\n",
    "    test_dataset = dataset[1].shuffle(seed=seed).select(range(num_test_samples))\n",
    "\n",
    "# length of the training and test datasets\n",
    "print(f\"Number of training examples: {len(train_dataset)}\")\n",
    "print(f\"Number of test examples: {len(test_dataset)}\")\n",
    "\n",
    "# get number of classes\n",
    "num_classes = train_dataset.features['label'].num_classes\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting and Displaying a Subset of AG News Training Dataset with Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Desiring Stability Redskins coach Joe Gibbs expects few major personnel changes in the offseason and wants to instill a culture of stability in Washington.</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Will Putin #39;s Power Play Make Russia Safer? Outwardly, Russia has not changed since the barrage of terrorist attacks that culminated in the school massacre in Beslan on Sept.</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U2 pitches for Apple New iTunes ads airing during baseball games Tuesday will feature the advertising-shy Irish rockers.</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S African TV in beheading blunder Public broadcaster SABC apologises after news bulletin shows footage of American beheaded in Iraq.</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Cosmic Storm: When Galaxy Clusters Collide Astronomers have found what they are calling the perfect cosmic storm, a galaxy cluster pile-up so powerful its energy output is second only to the Big Bang.</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West sets deadline for Iran to freeze uranium enrichment Four western countries set the scene yesterday for a showdown with Iran by demanding that it freeze its uranium enrichment activities immediately.</td>\n",
       "      <td>0</td>\n",
       "      <td>World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Computer Assoc. Cuts 800 Jobs Worldwide (AP) AP - Computer Associates International Inc. announced a restructuring plan Wednesday that would reduce its work force by 800 people worldwide, saving the business software maker  #36;70 million annually once the plan is fully implemented.</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CA Opens Utility Pricing for Mainframes Keeping its promise to migrate toward more flexible pricing for its software, Computer Associates (Quote, Chart) has unleashed Measured Workload Pricing for its mainframe management products.</td>\n",
       "      <td>3</td>\n",
       "      <td>Sci/Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Economy builds steam in KC Fed district The economy continued to strengthen in September and early October in the Great Plains and Rocky Mountain regions covered by the Tenth Federal Reserve District, the Federal Reserve Bank of Kansas City said Wednesday.</td>\n",
       "      <td>2</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                          text  \\\n",
       "0                                                                                                            Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.   \n",
       "1                                                                                                                                  Desiring Stability Redskins coach Joe Gibbs expects few major personnel changes in the offseason and wants to instill a culture of stability in Washington.   \n",
       "2                                                                                                            Will Putin #39;s Power Play Make Russia Safer? Outwardly, Russia has not changed since the barrage of terrorist attacks that culminated in the school massacre in Beslan on Sept.   \n",
       "3                                                                                                                                                                     U2 pitches for Apple New iTunes ads airing during baseball games Tuesday will feature the advertising-shy Irish rockers.   \n",
       "4                                                                                                                                                         S African TV in beheading blunder Public broadcaster SABC apologises after news bulletin shows footage of American beheaded in Iraq.   \n",
       "5                                                                                   A Cosmic Storm: When Galaxy Clusters Collide Astronomers have found what they are calling the perfect cosmic storm, a galaxy cluster pile-up so powerful its energy output is second only to the Big Bang.   \n",
       "6                                                                                  West sets deadline for Iran to freeze uranium enrichment Four western countries set the scene yesterday for a showdown with Iran by demanding that it freeze its uranium enrichment activities immediately.   \n",
       "7  Computer Assoc. Cuts 800 Jobs Worldwide (AP) AP - Computer Associates International Inc. announced a restructuring plan Wednesday that would reduce its work force by 800 people worldwide, saving the business software maker  #36;70 million annually once the plan is fully implemented.   \n",
       "8                                                      CA Opens Utility Pricing for Mainframes Keeping its promise to migrate toward more flexible pricing for its software, Computer Associates (Quote, Chart) has unleashed Measured Workload Pricing for its mainframe management products.   \n",
       "9                             Economy builds steam in KC Fed district The economy continued to strengthen in September and early October in the Great Plains and Rocky Mountain regions covered by the Tenth Federal Reserve District, the Federal Reserve Bank of Kansas City said Wednesday.   \n",
       "\n",
       "   label     class  \n",
       "0      0     World  \n",
       "1      1    Sports  \n",
       "2      0     World  \n",
       "3      3  Sci/Tech  \n",
       "4      0     World  \n",
       "5      3  Sci/Tech  \n",
       "6      0     World  \n",
       "7      3  Sci/Tech  \n",
       "8      3  Sci/Tech  \n",
       "9      2  Business  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a subset of the training dataset\n",
    "num_examples = 10\n",
    "items = train_dataset.select(range(num_examples))\n",
    "\n",
    "# class labels\n",
    "class_labels = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
    "\n",
    "# create a dataframe from the dataset\n",
    "dataset_dict = { \n",
    "    \"text\": [item['text'] for item in items],\n",
    "    \"label\": [item['label'] for item in items],\n",
    "    \"class\": [class_labels[item['label']] for item in items]\n",
    "}\n",
    "df = pd.DataFrame(dataset_dict)\n",
    "\n",
    "# display the dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df.head(num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading GPT-2 Tokenizer and Sequence Classification Model with Padding Token Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer and model loaded successfully.\n",
      "Padding token: [PAD]\n",
      "Padding token ID: 50257\n",
      "\n",
      "Number of trainable parameters: 124443648\n",
      "\n",
      "GPT2ForSequenceClassification(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50258, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (score): Linear(in_features=768, out_features=4, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer and model\n",
    "try:\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=num_classes)\n",
    "    print(\"Tokenizer and model loaded successfully.\")\n",
    "except Exception as ex:\n",
    "    print(f\"An error occurred while loading the tokenizer and model: {ex}\")\n",
    "\n",
    "# add padding token\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # add padding token to tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))  # resize token embeddings in model\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # set pad token id in model config\n",
    "\n",
    "# move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Verify the padding token\n",
    "print(f\"Padding token: {tokenizer.pad_token}\")\n",
    "print(f\"Padding token ID: {tokenizer.pad_token_id}\\n\")\n",
    "\n",
    "# no. of trainable parameters\n",
    "print(f\"Number of trainable parameters: {model.num_parameters()}\\n\")\n",
    "# NOTE: number of trainable parameters: 124,443,652\n",
    "\n",
    "# print the model architecture\n",
    "print(model)\n",
    "# NOTE: last layer (score) is newly initialized with random weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenizing and Padding the First Five Training Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([5, 39])\n",
      "Input IDs:\n",
      "tensor([[43984,    75, 13410,  1582, 47557,   416,  8956, 29560,  7941,   423,\n",
      "          3181,   867, 11684,   290,  4736,   287, 19483,   284,   257, 17369,\n",
      "            11,   262,  1110,   706,  1248,   661,  3724,   287, 23171,   379,\n",
      "           257,  1964,  7903,    13, 50257, 50257, 50257, 50257, 50257],\n",
      "        [ 5960,  3428, 47865, 22038,  3985,  5689, 41071, 13423,  1178,  1688,\n",
      "          8213,  2458,   287,   262, 16349,   290,  3382,   284,   916,   359,\n",
      "           257,  3968,   286, 10159,   287,  2669,    13, 50257, 50257, 50257,\n",
      "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257],\n",
      "        [ 8743,  8144,  1303,  2670,    26,    82,  4333,  3811,  6889,  3284,\n",
      "          6895,   263,    30,  3806,   904,   306,    11,  3284,   468,   407,\n",
      "          3421,  1201,   262, 33633,   286,  7417,  3434,   326, 45200,   287,\n",
      "           262,  1524, 19050,   287, 30837,  9620,   319,  2362,    13],\n",
      "        [   52,    17, 22421,   329,  4196,   968,  4830,  9011, 31701,  1141,\n",
      "          9283,  1830,  3431,   481,  3895,   262,  8560,    12,  1477,    88,\n",
      "          8685,  3881,   364,    13, 50257, 50257, 50257, 50257, 50257, 50257,\n",
      "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257],\n",
      "        [   50,  5510,  3195,   287,   307, 33878,   698,  4625,  5094, 26661,\n",
      "         14719,  2749,  8453,  2696,   706,  1705, 40813,  2523,  9640,   286,\n",
      "          1605,   307, 15353,   287,  3908,    13, 50257, 50257, 50257, 50257,\n",
      "         50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]])\n",
      "\n",
      "Attention Mask shape: torch.Size([5, 39])\n",
      "Attention Mask:\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first five training examples\n",
    "texts = df['text'].tolist()[:5]\n",
    "\n",
    "# Tokenize the text with padding\n",
    "encoded_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Print the tokenized inputs\n",
    "input_ids = encoded_inputs['input_ids']\n",
    "attention_mask = encoded_inputs['attention_mask']\n",
    "print(f\"Input IDs shape: {input_ids.shape}\")\n",
    "print(f\"Input IDs:\\n{input_ids}\\n\")\n",
    "print(f\"Attention Mask shape: {attention_mask.shape}\")\n",
    "print(f\"Attention Mask:\\n{attention_mask}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenization, DataLoader Setup, and Model Training/Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "\n",
    "# create DataLoader\n",
    "def get_dataloader(dataset, batch_size=8):\n",
    "    input_ids = torch.tensor(dataset['input_ids'])\n",
    "    attention_mask = torch.tensor(dataset['attention_mask'])\n",
    "    labels = torch.tensor(dataset['label'])\n",
    "\n",
    "    dataset = TensorDataset(input_ids, attention_mask, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "# training loop\n",
    "def train(model: torch.nn.Module, dataloader: DataLoader, optimizer: torch.optim.Optimizer, \n",
    "          scheduler: torch.optim.lr_scheduler.LambdaLR, device: torch.device, print_every: int = 250):\n",
    "    model.train()\n",
    "\n",
    "    # initialize variable to store total loss\n",
    "    total_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
    "        # move batch to device and unpack\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "        # backward pass and optimization step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # update total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # print loss periodically\n",
    "        if batch_idx % print_every == 0:\n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            print(f\"Batch {batch_idx}/{num_batches}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # calculate average loss\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "# evaluation loop\n",
    "def evaluate(model: torch.nn.Module, dataloader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    # initialize variables to store loss and accuracy\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
    "            # move batch to device and unpack\n",
    "            input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
    "\n",
    "            # update counts\n",
    "            total_loss += loss.item()\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    # calculate average loss and accuracy\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "# print model architecture and number of trainable parameters\n",
    "def print_model(model: torch.nn.Module, num_show_parameters=3):\n",
    "    # print model architecture\n",
    "    print(model)\n",
    "    print(f\"Number of trainable parameters: {model.num_parameters()}\\n\")\n",
    "\n",
    "    # print model parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Parameter: {name}, Trainable: {param.requires_grad}\")\n",
    "        params_head = param.flatten()[:num_show_parameters].tolist()\n",
    "        params_head = [f\"{p:.4f}\" for p in params_head]\n",
    "        print(f\"Size: {param.size()}; First three parameters: {params_head}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating Model Accuracy on Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954c89f145c44a8c94b0a1e2f2cf26dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/950 [00:00<?, ?it/s]c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Evaluation: 100%|██████████| 950/950 [02:59<00:00,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.2461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on training and test datasets\n",
    "batch_size = 8\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "train_dataloader = get_dataloader(tokenized_train_dataset, batch_size=batch_size)\n",
    "# _, train_accuracy = evaluate(model, train_dataloader, device)\n",
    "# print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "test_dataloader = get_dataloader(tokenized_test_dataset, batch_size=batch_size)\n",
    "_, test_accuracy = evaluate(model, test_dataloader, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Parameter-Efficient Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Configuring and Initializing LoRA Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\peft\\tuners\\lora\\layer.py:1091: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 442,368 || all params: 124,886,016 || trainable%: 0.3542\n",
      "\n",
      "========== Trainable Layers ==========\n",
      "Layer Name: base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight\n",
      "Layer Name: base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight\n",
      "Layer Name: base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight\n",
      "Layer Name: base_model.model.score.weight\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "# configure LoRA model\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # rank of the low-rank adaptation\n",
    "    lora_alpha=32,  # scaling factor\n",
    "    lora_dropout=0.1,  # dropout rate\n",
    "    target_modules=[\"attn.c_attn\", \"attn.c_proj\"]  # target modules to adapt\n",
    ")\n",
    "\n",
    "# get LoRA model\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.print_trainable_parameters()\n",
    "lora_model = lora_model.to(device)\n",
    "\n",
    "# set last layer to be trainable\n",
    "print(\"\\n========== Trainable Layers ==========\")\n",
    "for name, param in lora_model.named_parameters():\n",
    "    if \"score\" in name:\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    # print name of layer with trainable parameters\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer Name: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display LoRA Model Architecture and Trainable Parameters Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2ForSequenceClassification(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(50258, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2SdpaAttention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (c_proj): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (score): Linear(in_features=768, out_features=4, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of trainable parameters: 124886016\n",
      "\n",
      "Parameter: base_model.model.transformer.wte.weight, Trainable: False\n",
      "Size: torch.Size([50258, 768]); First three parameters: ['-0.1101', '-0.0393', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.wpe.weight, Trainable: False\n",
      "Size: torch.Size([1024, 768]); First three parameters: ['-0.0188', '-0.1974', '0.0040']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2232', '0.1820', '0.1534']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0037', '0.0272', '-0.0640']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.4738', '-0.2614', '-0.0978']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.4803', '-0.5254', '-0.4293']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0099', '-0.0318', '-0.0299']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.3127', '-0.1874', '0.0980']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1503', '-0.1543', '-0.1466']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0105', '-0.0315', '-0.0288']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1310', '0.2093', '0.2066']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0425', '0.0326', '0.0045']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0942', '0.0982', '-0.0321']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['0.0396', '-0.0881', '-0.1402']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.1066', '0.1528', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0450', '0.0323', '-0.0885']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2086', '0.2185', '0.2183']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0036', '-0.0062', '-0.0036']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2906', '0.3057', '0.0302']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0092', '-0.1241', '-0.2280']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0137', '-0.0249', '-0.0297']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0971', '-0.0016', '0.1122']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0604', '-0.0224', '-0.0437']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0062', '-0.0175', '0.0309']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2241', '0.2531', '0.2446']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0202', '0.0216', '-0.0155']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0078', '-0.2255', '-0.0207']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0624', '-0.1828', '-0.0202']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.1112', '-0.0263', '-0.0332']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0231', '0.0461', '-0.0553']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1871', '0.2227', '0.2366']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0049', '-0.0015', '0.0018']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2659', '0.0279', '0.0728']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0541', '-0.0644', '0.0311']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0218', '0.0270', '-0.0193']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0131', '-0.0666', '-0.0697']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0207', '-0.2638', '-0.1094']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0245', '-0.0025', '-0.0190']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2646', '0.3057', '0.2836']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0432', '0.0246', '0.0044']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0137', '0.3680', '-0.1068']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0138', '-0.2094', '-0.0488']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0240', '-0.2091', '-0.0291']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0654', '0.1081', '0.0429']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2725', '0.3078', '0.3174']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0236', '0.0040', '0.0108']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.0180', '-0.1333', '0.1339']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.2251', '-0.0644', '0.0223']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0011', '0.0122', '-0.0111']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.0660', '-0.0059', '-0.0359']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0142', '-0.2404', '-0.0183']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0247', '0.0281', '-0.0110']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2822', '0.3131', '0.3034']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0220', '0.0357', '0.0406']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0354', '-0.0083', '-0.0900']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1992', '0.0224', '-0.1989']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0766', '0.0050', '-0.0819']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0233', '0.1056', '-0.0531']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2971', '0.3330', '0.3428']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0224', '0.0061', '0.0158']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0542', '0.1037', '-0.1203']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0302', '0.1053', '0.1579']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0144', '0.0258', '-0.0342']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.1220', '-0.0009', '0.0201']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.1335', '-0.1202', '-0.0200']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0229', '0.0188', '0.0327']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2607', '0.2783']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0358', '0.0014', '0.0283']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0004', '-0.1200', '-0.0123']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0643', '-0.2986', '-0.1127']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0166', '0.0334', '-0.0259']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0590', '0.1573', '-0.0840']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3461', '0.3910', '0.4093']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0201', '0.0202', '0.0177']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.1861', '-0.1976', '0.0349']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0436', '0.0295', '0.0850']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0293', '0.0028', '0.0102']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0318', '0.1413', '-0.0693']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0348', '-0.0308', '-0.0073']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0257', '0.0290', '0.0246']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2686', '0.2705', '0.2811']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0420', '0.0188', '0.0365']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0246', '0.1288', '0.0653']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0782', '-0.0395', '-0.2416']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0648', '0.1070', '0.1007']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0265', '0.0347', '-0.0500']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3310', '0.3408', '0.3612']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0233', '0.0142', '0.0237']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.1109', '-0.0750', '0.0721']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0380', '0.1714', '-0.1409']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0180', '0.0249', '0.0118']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0463', '-0.1530', '0.0253']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0478', '-0.0351', '0.0270']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0333', '0.0319', '0.0013']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2588', '0.2482', '0.2724']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0450', '0.0095', '0.0170']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1218', '0.0713', '0.0619']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0303', '-0.0798', '-0.0008']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0970', '-0.0954', '0.0650']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0328', '0.1068', '-0.0207']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3551', '0.3564', '0.3759']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0303', '0.0209', '0.0318']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0951', '0.2815', '0.0759']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.3779', '0.0767', '0.0019']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0143', '-0.0352', '-0.0328']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0780', '-0.0183', '0.1131']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0378', '-0.0261', '0.0411']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0205', '-0.0002', '-0.0060']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2529', '0.2646']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0480', '0.0318', '0.0346']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0463', '0.0148', '0.0833']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0441', '-0.0103', '-0.0770']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0227', '-0.0343', '0.1083']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0030', '-0.0035', '-0.0502']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3518', '0.3381', '0.3564']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0266', '0.0141', '0.0361']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0490', '-0.1354', '0.0887']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0167', '-0.3909', '-0.1419']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0254', '0.0032', '0.0217']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0031', '0.0537', '-0.0047']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0141', '0.0153', '0.0148']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0125', '0.0359', '0.0240']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2555', '0.2643']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0265', '0.0306', '0.0328']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0728', '0.2308', '0.0563']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1121', '-0.1224', '-0.1870']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0882', '-0.0182', '-0.0571']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0588', '-0.0151', '-0.1270']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3815', '0.3605', '0.3697']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0305', '0.0109', '0.0433']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0709', '-0.1273', '0.1836']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0571', '0.0355', '-0.0991']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0152', '0.0121', '-0.0185']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.1317', '-0.1278', '0.0167']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0726', '0.1233', '0.0287']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0341', '0.0175', '-0.0117']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2713', '0.2568', '0.2734']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0464', '0.0140', '0.0420']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1263', '0.1003', '0.0432']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1567', '-0.0586', '-0.1862']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.2813', '-0.0430', '-0.1807']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0466', '-0.1099', '-0.2726']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.4269', '0.3799', '0.3893']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0305', '0.0060', '0.0488']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.2200', '0.2637', '0.0422']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0301', '0.1360', '-0.3842']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0271', '-0.0115', '0.0088']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0077', '-0.5188', '0.0783']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0124', '0.0143', '-0.0045']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0064', '0.0269', '-0.0079']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2976', '0.2666', '0.2978']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0104', '0.0138', '0.0283']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0470', '-0.1844', '0.0954']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0678', '0.0492', '-0.1440']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0526', '0.2037', '-0.2281']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0381', '0.0256', '-0.2010']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.5293', '0.4873', '0.4876']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0510', '0.0053', '0.0720']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2175', '0.0608', '-0.0637']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.2222', '0.0549', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0312', '-0.0250', '0.0265']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.1122', '0.1509', '0.0699']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1185', '-0.1396', '-0.1737']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0008', '0.0101', '-0.0090']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0000', '0.0000', '0.0000']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.4990', '0.4716', '0.5410']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0020', '0.0201', '0.0383']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1440', '0.2177', '-0.0821']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0382', '-0.1637', '0.2821']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0681', '0.0920', '-0.0310']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1057', '0.1188', '0.0067']\n",
      "\n",
      "Parameter: base_model.model.transformer.ln_f.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['1.3971', '1.3750', '1.8870']\n",
      "\n",
      "Parameter: base_model.model.transformer.ln_f.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0011', '0.0365', '-0.0673']\n",
      "\n",
      "Parameter: base_model.model.score.weight, Trainable: True\n",
      "Size: torch.Size([4, 768]); First three parameters: ['-0.0229', '0.0097', '-0.0034']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show model before training\n",
    "print_model(lora_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and Evaluating the LoRA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/15000 [00:00<2:32:39,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0/15000, Loss: 6.1291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 251/15000 [02:22<2:21:09,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 250/15000, Loss: 2.6859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 501/15000 [04:46<2:19:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 500/15000, Loss: 2.0398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 751/15000 [07:10<2:16:37,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 750/15000, Loss: 1.7247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 1001/15000 [09:34<2:15:47,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000/15000, Loss: 1.5148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 1251/15000 [11:57<2:08:37,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1250/15000, Loss: 1.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 1501/15000 [14:18<2:06:54,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1500/15000, Loss: 1.2077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 1751/15000 [16:42<2:09:03,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1750/15000, Loss: 1.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 2001/15000 [19:07<2:04:33,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000/15000, Loss: 1.0109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 2251/15000 [21:31<2:03:46,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2250/15000, Loss: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 2501/15000 [23:55<1:59:43,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2500/15000, Loss: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 2751/15000 [26:19<1:57:46,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2750/15000, Loss: 0.8382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 3001/15000 [28:44<1:56:45,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000/15000, Loss: 0.7956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 3251/15000 [31:10<1:54:24,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3250/15000, Loss: 0.7611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 3501/15000 [33:35<1:50:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3500/15000, Loss: 0.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 3751/15000 [36:00<1:47:33,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3750/15000, Loss: 0.7035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 4001/15000 [38:25<1:46:43,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000/15000, Loss: 0.6812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  28%|██▊       | 4251/15000 [40:49<1:43:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4250/15000, Loss: 0.6595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 4501/15000 [43:13<1:41:09,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4500/15000, Loss: 0.6394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  32%|███▏      | 4751/15000 [45:39<1:42:20,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4750/15000, Loss: 0.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 5001/15000 [48:04<1:35:41,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5000/15000, Loss: 0.6054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|███▌      | 5251/15000 [50:30<1:34:18,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5250/15000, Loss: 0.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  37%|███▋      | 5501/15000 [52:54<1:31:27,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5500/15000, Loss: 0.5791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  38%|███▊      | 5751/15000 [55:19<1:29:35,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5750/15000, Loss: 0.5672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 6001/15000 [57:44<1:27:08,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6000/15000, Loss: 0.5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  42%|████▏     | 6251/15000 [1:00:08<1:23:26,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6250/15000, Loss: 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|████▎     | 6501/15000 [1:02:31<1:20:44,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6500/15000, Loss: 0.5360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  45%|████▌     | 6751/15000 [1:04:56<1:18:41,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6750/15000, Loss: 0.5257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  47%|████▋     | 7001/15000 [1:07:22<1:19:23,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7000/15000, Loss: 0.5174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████▊     | 7251/15000 [1:09:51<1:16:43,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7250/15000, Loss: 0.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 7501/15000 [1:12:20<1:14:20,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7500/15000, Loss: 0.5032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|█████▏    | 7751/15000 [1:14:48<1:10:54,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7750/15000, Loss: 0.4964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  53%|█████▎    | 8001/15000 [1:17:15<1:07:40,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8000/15000, Loss: 0.4902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 8251/15000 [1:19:41<1:04:59,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8250/15000, Loss: 0.4845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  57%|█████▋    | 8501/15000 [1:22:05<1:02:34,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8500/15000, Loss: 0.4793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  58%|█████▊    | 8751/15000 [1:24:28<59:13,  1.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8750/15000, Loss: 0.4741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 9001/15000 [1:26:51<57:13,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9000/15000, Loss: 0.4684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  62%|██████▏   | 9251/15000 [1:29:14<54:44,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9250/15000, Loss: 0.4633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  63%|██████▎   | 9501/15000 [1:31:37<52:31,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9500/15000, Loss: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  65%|██████▌   | 9751/15000 [1:34:00<50:09,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9750/15000, Loss: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 10001/15000 [1:36:23<47:31,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10000/15000, Loss: 0.4495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  68%|██████▊   | 10251/15000 [1:38:45<45:11,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10250/15000, Loss: 0.4454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 10501/15000 [1:41:08<42:34,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10500/15000, Loss: 0.4409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  72%|███████▏  | 10751/15000 [1:43:32<40:14,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10750/15000, Loss: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  73%|███████▎  | 11001/15000 [1:45:55<38:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11000/15000, Loss: 0.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  75%|███████▌  | 11251/15000 [1:48:18<35:43,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11250/15000, Loss: 0.4302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  77%|███████▋  | 11501/15000 [1:50:41<33:21,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11500/15000, Loss: 0.4271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|███████▊  | 11751/15000 [1:53:04<31:09,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11750/15000, Loss: 0.4238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 12001/15000 [1:55:28<28:53,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12000/15000, Loss: 0.4202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  82%|████████▏ | 12251/15000 [1:57:51<26:22,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12250/15000, Loss: 0.4174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████▎ | 12501/15000 [2:00:15<23:57,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12500/15000, Loss: 0.4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  85%|████████▌ | 12751/15000 [2:02:38<21:27,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12750/15000, Loss: 0.4113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|████████▋ | 13001/15000 [2:05:02<19:14,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13000/15000, Loss: 0.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  88%|████████▊ | 13251/15000 [2:07:26<16:38,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13250/15000, Loss: 0.4069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 13501/15000 [2:09:50<14:32,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13500/15000, Loss: 0.4044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  92%|█████████▏| 13751/15000 [2:12:16<12:21,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13750/15000, Loss: 0.4020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  93%|█████████▎| 14001/15000 [2:14:44<09:34,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14000/15000, Loss: 0.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  95%|█████████▌| 14251/15000 [2:17:06<07:09,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14250/15000, Loss: 0.3976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  97%|█████████▋| 14501/15000 [2:19:31<04:42,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14500/15000, Loss: 0.3952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  98%|█████████▊| 14751/15000 [2:21:55<02:21,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14750/15000, Loss: 0.3935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15000/15000 [2:24:15<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 950/950 [03:24<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Loss: 0.2689, Eval Accuracy: 0.9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "num_epochs = 1\n",
    "learning_rate = 2e-5\n",
    "num_warmup_steps = 0\n",
    "\n",
    "# define optimizer and scheduler\n",
    "optimizer = AdamW(lora_model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs  # total number of training steps\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=total_steps)\n",
    "\n",
    "# training and evaluation\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    train_loss = train(lora_model, train_dataloader, optimizer, scheduler, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "    eval_loss, eval_accuracy = evaluate(lora_model, test_dataloader, device)\n",
    "    print(f\"Eval Loss: {eval_loss:.4f}, Eval Accuracy: {eval_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Model Evaluation and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2ForSequenceClassification(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(50258, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2SdpaAttention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (c_proj): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (score): Linear(in_features=768, out_features=4, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of trainable parameters: 124886016\n",
      "\n",
      "Parameter: base_model.model.transformer.wte.weight, Trainable: False\n",
      "Size: torch.Size([50258, 768]); First three parameters: ['-0.1101', '-0.0393', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.wpe.weight, Trainable: False\n",
      "Size: torch.Size([1024, 768]); First three parameters: ['-0.0188', '-0.1974', '0.0040']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2232', '0.1820', '0.1534']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0037', '0.0272', '-0.0640']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.4738', '-0.2614', '-0.0978']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.4803', '-0.5254', '-0.4293']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0078', '-0.0343', '-0.0369']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0014', '0.0040', '-0.0032']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.3127', '-0.1874', '0.0980']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1503', '-0.1543', '-0.1466']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0088', '-0.0357', '-0.0315']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0004', '0.0004', '0.0017']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1310', '0.2093', '0.2066']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0425', '0.0326', '0.0045']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0942', '0.0982', '-0.0321']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['0.0396', '-0.0881', '-0.1402']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.1066', '0.1528', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0450', '0.0323', '-0.0885']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2086', '0.2185', '0.2183']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0036', '-0.0062', '-0.0036']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2906', '0.3057', '0.0302']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0092', '-0.1241', '-0.2280']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0262', '-0.0291', '-0.0337']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0003', '0.0013', '-0.0008']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0971', '-0.0016', '0.1122']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0604', '-0.0224', '-0.0437']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0104', '-0.0189', '0.0257']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0017', '-0.0016', '0.0013']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2241', '0.2531', '0.2446']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0202', '0.0216', '-0.0155']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0078', '-0.2255', '-0.0207']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0624', '-0.1828', '-0.0202']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.1112', '-0.0263', '-0.0332']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0231', '0.0461', '-0.0553']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1871', '0.2227', '0.2366']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0049', '-0.0015', '0.0018']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2659', '0.0279', '0.0728']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0541', '-0.0644', '0.0311']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0305', '0.0268', '-0.0155']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0035', '0.0033', '0.0031']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0131', '-0.0666', '-0.0697']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0207', '-0.2638', '-0.1094']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0265', '0.0056', '-0.0263']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0001', '0.0004', '0.0001']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2646', '0.3057', '0.2836']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0432', '0.0246', '0.0044']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0137', '0.3680', '-0.1068']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0138', '-0.2094', '-0.0488']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0240', '-0.2091', '-0.0291']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0654', '0.1081', '0.0429']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2725', '0.3078', '0.3174']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0236', '0.0040', '0.0108']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.0180', '-0.1333', '0.1339']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.2251', '-0.0644', '0.0223']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0072', '0.0050', '-0.0149']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['-0.0030', '0.0015', '-0.0026']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.0660', '-0.0059', '-0.0359']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0142', '-0.2404', '-0.0183']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0163', '0.0330', '-0.0195']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0021', '-0.0027', '-0.0038']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2822', '0.3131', '0.3034']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0220', '0.0357', '0.0406']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0354', '-0.0083', '-0.0900']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1992', '0.0224', '-0.1989']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0766', '0.0050', '-0.0819']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0233', '0.1056', '-0.0531']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2971', '0.3330', '0.3428']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0224', '0.0061', '0.0158']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0542', '0.1037', '-0.1203']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0302', '0.1053', '0.1579']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0215', '0.0361', '-0.0321']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0005', '0.0013', '-0.0010']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.1220', '-0.0009', '0.0201']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.1335', '-0.1202', '-0.0200']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0288', '0.0235', '0.0229']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0026', '0.0030', '0.0046']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2607', '0.2783']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0358', '0.0014', '0.0283']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0004', '-0.1200', '-0.0123']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0643', '-0.2986', '-0.1127']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0166', '0.0334', '-0.0259']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0590', '0.1573', '-0.0840']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3461', '0.3910', '0.4093']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0201', '0.0202', '0.0177']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.1861', '-0.1976', '0.0349']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0436', '0.0295', '0.0850']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0332', '0.0031', '0.0167']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0029', '0.0038', '-0.0028']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0318', '0.1413', '-0.0693']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0348', '-0.0308', '-0.0073']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0215', '0.0241', '0.0222']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0012', '0.0018', '0.0022']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2686', '0.2705', '0.2811']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0420', '0.0188', '0.0365']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0246', '0.1288', '0.0653']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0782', '-0.0395', '-0.2416']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0648', '0.1070', '0.1007']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0265', '0.0347', '-0.0500']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3310', '0.3408', '0.3612']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0233', '0.0142', '0.0237']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.1109', '-0.0750', '0.0721']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0380', '0.1714', '-0.1409']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0150', '0.0283', '0.0110']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['-0.0053', '0.0025', '0.0063']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0463', '-0.1530', '0.0253']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0478', '-0.0351', '0.0270']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0402', '0.0342', '0.0025']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0001', '-0.0020', '0.0015']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2588', '0.2482', '0.2724']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0450', '0.0095', '0.0170']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1218', '0.0713', '0.0619']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0303', '-0.0798', '-0.0008']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0970', '-0.0954', '0.0650']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0328', '0.1068', '-0.0207']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3551', '0.3564', '0.3759']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0303', '0.0209', '0.0318']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0951', '0.2815', '0.0759']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.3779', '0.0767', '0.0019']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0128', '-0.0396', '-0.0376']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['-0.0018', '0.0003', '0.0005']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0780', '-0.0183', '0.1131']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0378', '-0.0261', '0.0411']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0133', '-0.0006', '-0.0020']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0039', '0.0019', '-0.0004']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2529', '0.2646']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0480', '0.0318', '0.0346']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0463', '0.0148', '0.0833']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0441', '-0.0103', '-0.0770']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0227', '-0.0343', '0.1083']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0030', '-0.0035', '-0.0502']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3518', '0.3381', '0.3564']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0266', '0.0141', '0.0361']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0490', '-0.1354', '0.0887']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0167', '-0.3909', '-0.1419']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0251', '0.0015', '0.0194']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0011', '0.0001', '0.0001']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0031', '0.0537', '-0.0047']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0141', '0.0153', '0.0148']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0067', '0.0456', '0.0322']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0039', '-0.0019', '0.0055']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2555', '0.2643']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0265', '0.0306', '0.0328']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0728', '0.2308', '0.0563']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1121', '-0.1224', '-0.1870']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0882', '-0.0182', '-0.0571']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0588', '-0.0151', '-0.1270']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3815', '0.3605', '0.3697']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0305', '0.0109', '0.0433']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0709', '-0.1273', '0.1836']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0571', '0.0355', '-0.0991']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0240', '0.0054', '-0.0295']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0038', '0.0041', '-0.0037']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.1317', '-0.1278', '0.0167']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0726', '0.1233', '0.0287']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0536', '0.0148', '-0.0099']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0014', '0.0007', '-0.0079']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2713', '0.2568', '0.2734']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0464', '0.0140', '0.0420']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1263', '0.1003', '0.0432']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1567', '-0.0586', '-0.1862']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.2813', '-0.0430', '-0.1807']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0466', '-0.1099', '-0.2726']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.4269', '0.3799', '0.3893']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0305', '0.0060', '0.0488']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.2200', '0.2637', '0.0422']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0301', '0.1360', '-0.3842']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0267', '-0.0051', '0.0070']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0048', '-0.0038', '0.0052']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0077', '-0.5188', '0.0783']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0124', '0.0143', '-0.0045']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0054', '0.0393', '-0.0267']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0002', '0.0047', '0.0049']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2976', '0.2666', '0.2978']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0104', '0.0138', '0.0283']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0470', '-0.1844', '0.0954']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0678', '0.0492', '-0.1440']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0526', '0.2037', '-0.2281']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0381', '0.0256', '-0.2010']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.5293', '0.4873', '0.4876']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0510', '0.0053', '0.0720']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2175', '0.0608', '-0.0637']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.2222', '0.0549', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0308', '-0.0226', '0.0222']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0040', '-0.0042', '-0.0025']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.1122', '0.1509', '0.0699']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1185', '-0.1396', '-0.1737']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight, Trainable: True\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0019', '0.0107', '-0.0078']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight, Trainable: True\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0143', '0.0081', '-0.0015']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.4990', '0.4716', '0.5410']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0020', '0.0201', '0.0383']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1440', '0.2177', '-0.0821']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0382', '-0.1637', '0.2821']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0681', '0.0920', '-0.0310']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1057', '0.1188', '0.0067']\n",
      "\n",
      "Parameter: base_model.model.transformer.ln_f.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['1.3971', '1.3750', '1.8870']\n",
      "\n",
      "Parameter: base_model.model.transformer.ln_f.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0011', '0.0365', '-0.0673']\n",
      "\n",
      "Parameter: base_model.model.score.weight, Trainable: True\n",
      "Size: torch.Size([4, 768]); First three parameters: ['-0.0408', '0.0185', '-0.0019']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\peft\\utils\\save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: lora_gpt2_ag_news\n"
     ]
    }
   ],
   "source": [
    "# show model after training\n",
    "print_model(lora_model)\n",
    "\n",
    "\n",
    "# save models\n",
    "model_path = \"lora_gpt2_ag_news\"\n",
    "lora_model.save_pretrained(f\"{model_path}/lora_adapter\")\n",
    "# save the score weights (output layer) separately\n",
    "torch.save(lora_model.score.weight, f\"{model_path}/score_weights.pth\")\n",
    "print(f\"Model saved at: {model_path}\")\n",
    "\n",
    "# delete models and variables\n",
    "del model, lora_model, optimizer, scheduler, tokenizer, lora_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Inference with a PEFT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading and Preparing the Fine-Tuned LoRA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_5816\\676792674.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  score_weights = torch.load(f\"{model_path}/score_weights.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModel(\n",
      "  (base_model): LoraModel(\n",
      "    (model): GPT2ForSequenceClassification(\n",
      "      (transformer): GPT2Model(\n",
      "        (wte): Embedding(50258, 768)\n",
      "        (wpe): Embedding(1024, 768)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (h): ModuleList(\n",
      "          (0-11): 12 x GPT2Block(\n",
      "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): GPT2SdpaAttention(\n",
      "              (c_attn): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=2304, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (c_proj): lora.Linear(\n",
      "                (base_layer): Conv1D()\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): GPT2MLP(\n",
      "              (c_fc): Conv1D()\n",
      "              (c_proj): Conv1D()\n",
      "              (act): NewGELUActivation()\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (score): Linear(in_features=768, out_features=4, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Number of trainable parameters: 124886016\n",
      "\n",
      "Parameter: base_model.model.transformer.wte.weight, Trainable: False\n",
      "Size: torch.Size([50258, 768]); First three parameters: ['-0.1101', '-0.0393', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.wpe.weight, Trainable: False\n",
      "Size: torch.Size([1024, 768]); First three parameters: ['-0.0188', '-0.1974', '0.0040']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2232', '0.1820', '0.1534']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0037', '0.0272', '-0.0640']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.4738', '-0.2614', '-0.0978']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.4803', '-0.5254', '-0.4293']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0078', '-0.0343', '-0.0369']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0014', '0.0040', '-0.0032']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.3127', '-0.1874', '0.0980']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1503', '-0.1543', '-0.1466']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0088', '-0.0357', '-0.0315']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0004', '0.0004', '0.0017']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1310', '0.2093', '0.2066']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0425', '0.0326', '0.0045']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0942', '0.0982', '-0.0321']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['0.0396', '-0.0881', '-0.1402']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.1066', '0.1528', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.0.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0450', '0.0323', '-0.0885']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2086', '0.2185', '0.2183']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0036', '-0.0062', '-0.0036']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2906', '0.3057', '0.0302']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0092', '-0.1241', '-0.2280']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0262', '-0.0291', '-0.0337']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0003', '0.0013', '-0.0008']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0971', '-0.0016', '0.1122']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0604', '-0.0224', '-0.0437']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0104', '-0.0189', '0.0257']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0017', '-0.0016', '0.0013']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2241', '0.2531', '0.2446']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0202', '0.0216', '-0.0155']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0078', '-0.2255', '-0.0207']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0624', '-0.1828', '-0.0202']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.1112', '-0.0263', '-0.0332']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.1.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0231', '0.0461', '-0.0553']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1871', '0.2227', '0.2366']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0049', '-0.0015', '0.0018']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2659', '0.0279', '0.0728']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0541', '-0.0644', '0.0311']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0305', '0.0268', '-0.0155']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0035', '0.0033', '0.0031']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0131', '-0.0666', '-0.0697']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0207', '-0.2638', '-0.1094']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0265', '0.0056', '-0.0263']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0001', '0.0004', '0.0001']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2646', '0.3057', '0.2836']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0432', '0.0246', '0.0044']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0137', '0.3680', '-0.1068']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0138', '-0.2094', '-0.0488']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0240', '-0.2091', '-0.0291']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.2.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0654', '0.1081', '0.0429']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2725', '0.3078', '0.3174']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0236', '0.0040', '0.0108']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.0180', '-0.1333', '0.1339']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.2251', '-0.0644', '0.0223']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0072', '0.0050', '-0.0149']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['-0.0030', '0.0015', '-0.0026']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.0660', '-0.0059', '-0.0359']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0142', '-0.2404', '-0.0183']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0163', '0.0330', '-0.0195']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0021', '-0.0027', '-0.0038']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2822', '0.3131', '0.3034']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0220', '0.0357', '0.0406']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0354', '-0.0083', '-0.0900']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1992', '0.0224', '-0.1989']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0766', '0.0050', '-0.0819']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.3.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0233', '0.1056', '-0.0531']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2971', '0.3330', '0.3428']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0224', '0.0061', '0.0158']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0542', '0.1037', '-0.1203']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0302', '0.1053', '0.1579']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0215', '0.0361', '-0.0321']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0005', '0.0013', '-0.0010']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.1220', '-0.0009', '0.0201']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.1335', '-0.1202', '-0.0200']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0288', '0.0235', '0.0229']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0026', '0.0030', '0.0046']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2607', '0.2783']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0358', '0.0014', '0.0283']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0004', '-0.1200', '-0.0123']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0643', '-0.2986', '-0.1127']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0166', '0.0334', '-0.0259']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.4.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0590', '0.1573', '-0.0840']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3461', '0.3910', '0.4093']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0201', '0.0202', '0.0177']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.1861', '-0.1976', '0.0349']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0436', '0.0295', '0.0850']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0332', '0.0031', '0.0167']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0029', '0.0038', '-0.0028']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0318', '0.1413', '-0.0693']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0348', '-0.0308', '-0.0073']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0215', '0.0241', '0.0222']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0012', '0.0018', '0.0022']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2686', '0.2705', '0.2811']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0420', '0.0188', '0.0365']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0246', '0.1288', '0.0653']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0782', '-0.0395', '-0.2416']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0648', '0.1070', '0.1007']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.5.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0265', '0.0347', '-0.0500']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3310', '0.3408', '0.3612']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0233', '0.0142', '0.0237']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.1109', '-0.0750', '0.0721']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0380', '0.1714', '-0.1409']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0150', '0.0283', '0.0110']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['-0.0053', '0.0025', '0.0063']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0463', '-0.1530', '0.0253']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0478', '-0.0351', '0.0270']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0402', '0.0342', '0.0025']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0001', '-0.0020', '0.0015']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2588', '0.2482', '0.2724']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0450', '0.0095', '0.0170']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1218', '0.0713', '0.0619']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0303', '-0.0798', '-0.0008']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0970', '-0.0954', '0.0650']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.6.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0328', '0.1068', '-0.0207']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3551', '0.3564', '0.3759']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0303', '0.0209', '0.0318']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0951', '0.2815', '0.0759']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.3779', '0.0767', '0.0019']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0128', '-0.0396', '-0.0376']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['-0.0018', '0.0003', '0.0005']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0780', '-0.0183', '0.1131']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0378', '-0.0261', '0.0411']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0133', '-0.0006', '-0.0020']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0039', '0.0019', '-0.0004']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2529', '0.2646']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0480', '0.0318', '0.0346']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0463', '0.0148', '0.0833']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0441', '-0.0103', '-0.0770']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0227', '-0.0343', '0.1083']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.7.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0030', '-0.0035', '-0.0502']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3518', '0.3381', '0.3564']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0266', '0.0141', '0.0361']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0490', '-0.1354', '0.0887']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0167', '-0.3909', '-0.1419']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0251', '0.0015', '0.0194']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0011', '0.0001', '0.0001']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0031', '0.0537', '-0.0047']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0141', '0.0153', '0.0148']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0067', '0.0456', '0.0322']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0039', '-0.0019', '0.0055']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2568', '0.2555', '0.2643']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0265', '0.0306', '0.0328']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['0.0728', '0.2308', '0.0563']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1121', '-0.1224', '-0.1870']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['-0.0882', '-0.0182', '-0.0571']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.8.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0588', '-0.0151', '-0.1270']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.3815', '0.3605', '0.3697']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0305', '0.0109', '0.0433']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.0709', '-0.1273', '0.1836']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['0.0571', '0.0355', '-0.0991']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0240', '0.0054', '-0.0295']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0038', '0.0041', '-0.0037']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.1317', '-0.1278', '0.0167']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0726', '0.1233', '0.0287']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0536', '0.0148', '-0.0099']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0014', '0.0007', '-0.0079']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2713', '0.2568', '0.2734']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0464', '0.0140', '0.0420']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1263', '0.1003', '0.0432']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.1567', '-0.0586', '-0.1862']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.2813', '-0.0430', '-0.1807']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.9.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0466', '-0.1099', '-0.2726']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.4269', '0.3799', '0.3893']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0305', '0.0060', '0.0488']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['0.2200', '0.2637', '0.0422']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.0301', '0.1360', '-0.3842']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0267', '-0.0051', '0.0070']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0048', '-0.0038', '0.0052']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['-0.0077', '-0.5188', '0.0783']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0124', '0.0143', '-0.0045']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0054', '0.0393', '-0.0267']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['0.0002', '0.0047', '0.0049']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.2976', '0.2666', '0.2978']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0104', '0.0138', '0.0283']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.0470', '-0.1844', '0.0954']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0678', '0.0492', '-0.1440']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0526', '0.2037', '-0.2281']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.10.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0381', '0.0256', '-0.2010']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_1.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.5293', '0.4873', '0.4876']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_1.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0510', '0.0053', '0.0720']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 2304]); First three parameters: ['-0.2175', '0.0608', '-0.0637']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([2304]); First three parameters: ['-0.2222', '0.0549', '0.0331']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['0.0308', '-0.0226', '0.0222']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([2304, 8]); First three parameters: ['0.0040', '-0.0042', '-0.0025']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.base_layer.weight, Trainable: False\n",
      "Size: torch.Size([768, 768]); First three parameters: ['0.1122', '0.1509', '0.0699']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.base_layer.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1185', '-0.1396', '-0.1737']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight, Trainable: False\n",
      "Size: torch.Size([8, 768]); First three parameters: ['-0.0019', '0.0107', '-0.0078']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight, Trainable: False\n",
      "Size: torch.Size([768, 8]); First three parameters: ['-0.0143', '0.0081', '-0.0015']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_2.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.4990', '0.4716', '0.5410']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.ln_2.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['-0.0020', '0.0201', '0.0383']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_fc.weight, Trainable: False\n",
      "Size: torch.Size([768, 3072]); First three parameters: ['-0.1440', '0.2177', '-0.0821']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_fc.bias, Trainable: False\n",
      "Size: torch.Size([3072]); First three parameters: ['-0.0382', '-0.1637', '0.2821']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_proj.weight, Trainable: False\n",
      "Size: torch.Size([3072, 768]); First three parameters: ['0.0681', '0.0920', '-0.0310']\n",
      "\n",
      "Parameter: base_model.model.transformer.h.11.mlp.c_proj.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.1057', '0.1188', '0.0067']\n",
      "\n",
      "Parameter: base_model.model.transformer.ln_f.weight, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['1.3971', '1.3750', '1.8870']\n",
      "\n",
      "Parameter: base_model.model.transformer.ln_f.bias, Trainable: False\n",
      "Size: torch.Size([768]); First three parameters: ['0.0011', '0.0365', '-0.0673']\n",
      "\n",
      "Parameter: base_model.model.score.weight, Trainable: False\n",
      "Size: torch.Size([4, 768]); First three parameters: ['-0.0408', '0.0185', '-0.0019']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file\n",
    "\n",
    "\n",
    "# load tokenizer and model\n",
    "new_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "new_model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=num_classes)\n",
    "\n",
    "# add padding token\n",
    "new_tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # add padding token to tokenizer\n",
    "new_model.resize_token_embeddings(len(new_tokenizer))  # resize token embeddings in model\n",
    "new_model.config.pad_token_id = new_tokenizer.pad_token_id  # set pad token id in model config\n",
    "\n",
    "# recall model path\n",
    "model_path = \"lora_gpt2_ag_news\"\n",
    "# load LoRA config and weights\n",
    "loaded_lora_config = LoraConfig.from_pretrained(f\"{model_path}/lora_adapter\")\n",
    "weights = load_file(f\"{model_path}/lora_adapter/adapter_model.safetensors\")\n",
    "\n",
    "# get LoRA model\n",
    "loaded_lora_model = get_peft_model(new_model, loaded_lora_config)\n",
    "\n",
    "# replace model weights with loaded LoRA weights\n",
    "for name, param in loaded_lora_model.named_parameters():\n",
    "    # name e.g. 'base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight'\n",
    "    if 'lora_' in name:\n",
    "        assert 'default' in name, f\"Layer {name} is not a default layer\"\n",
    "        new_name = name.replace('.default', '')  # remove '.default' from the name\n",
    "        param.data.copy_(weights[new_name])  # replace the weights\n",
    "\n",
    "# replace score weights (output layer)\n",
    "score_weights = torch.load(f\"{model_path}/score_weights.pth\")\n",
    "loaded_lora_model.score.weight.data.copy_(score_weights)\n",
    "\n",
    "# move model to specified device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_lora_model = loaded_lora_model.to(device)\n",
    "print_model(loaded_lora_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluating the Loaded LoRA Model and Comparing Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 950/950 [03:18<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Model Loss: 0.2689, Loaded Model Accuracy: 0.9059\n",
      "\n",
      "Compare performance of original and trained models\n",
      "Original Model Accuracy: 24.61%\n",
      "Trained Model Accuracy: 90.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model\n",
    "loaded_model_loss, loaded_model_accuracy = evaluate(loaded_lora_model, test_dataloader, device)\n",
    "print(f\"Loaded Model Loss: {loaded_model_loss:.4f}, Loaded Model Accuracy: {loaded_model_accuracy:.4f}\", end=\"\\n\\n\")\n",
    "\n",
    "# compare performance of original and trained models\n",
    "print(\"Compare performance of original and trained models\")\n",
    "print(f\"Original Model Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Trained Model Accuracy: {loaded_model_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
